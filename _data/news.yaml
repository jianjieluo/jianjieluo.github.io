# News on home page
main:
  - "(July 2021) One paper accepted to [ICCV 2021](http://iccv2021.thecvf.com/home)."
  - "(June 2021) Presenting an invited talk at the [CVPR Embodied AI workshop](https://embodied-ai.org/) - ['Massive Datasets for Language-Guided Navigation Agents and Where to Find Them'](https://youtu.be/r5RmmXeUAwE)."
  - "(June 2021) Co-organizing a CVPR tutorial - [From VQA to VLN: Recent Advances in Vision-and-Language Research](https://vqa2vln-tutorial.github.io/)" 
  - "(February 2021) [RxR-Habitat challenge](https://ai.google.com/research/rxr/habitat?active_tab=leaderboard) launched for multilingual instruction-following in continuous environments!"
  - "(January 2021) Our paper on the evaluation of grounded navigation instructions is accepted to [EACL 2021](https://2021.eacl.org/)."
  - "(January 2021) Our [RxR challenge and leaderboard](https://ai.google.com/research/rxr/) for multilingual vision-and-language navigation is now open for submissions! We've also open-sourced [PanGEA](https://github.com/google-research/pangea), the annotation toolkit we developed to collect RxR."

all:
  - "(July 2021) One paper accepted to [ICCV 2021](http://iccv2021.thecvf.com/home)."
  - "(June 2021) Presenting an invited talk at the [CVPR Embodied AI workshop](https://embodied-ai.org/) - ['Massive Datasets for Language-Guided Navigation Agents and Where to Find Them'](https://youtu.be/r5RmmXeUAwE)."
  - "(June 2021) Co-organizing a CVPR tutorial - [From VQA to VLN: Recent Advances in Vision-and-Language Research](https://vqa2vln-tutorial.github.io/)"
  - "(February 2021) [RxR-Habitat Challenge](https://ai.google.com/research/rxr/habitat?active_tab=leaderboard) launched for multilingual instruction-following in continuous environments!"
  - "(January 2021) Our paper on the evaluation of grounded navigation instructions is accepted to [EACL 2021](https://2021.eacl.org/)."
  - "(January 2021) Our [RxR challenge and leaderboard](https://ai.google.com/research/rxr/) for multilingual vision-and-language navigation is now open for submissions! We've also open-sourced [PanGEA](https://github.com/google-research/pangea), the annotation toolkit we developed to collect RxR."
  - "(December 2020) Recognized as an [EMNLP 2020 outstanding reviewer](https://www.aclweb.org/anthology/2020.emnlp-main.0.pdf)."
  - "(October 2020) Excited to release our new [RxR dataset](https://github.com/google-research-datasets/RxR) for multilingual Vision-and-Language Navigation (VLN)."
  - "(October 2020) Our VLN sim-to-real paper is accepted to [CoRL 2020](https://www.robot-learning.org/)."
  - "(September 2020) Two papers accepted to [EMNLP 2020](https://2020.emnlp.org/)."
  - "(July 2020) Two papers accepted to [ECCV 2020](https://eccv2020.eu/)."
  - "(June 2020) Presenting an invited talk at the [VizWiz workshop](https://vizwiz.org/workshops/2020-workshop/) at [CVPR 2020](http://cvpr2020.thecvf.com/)."
  - "(February 2020) Our [REVERIE](https://arxiv.org/abs/1904.10151) paper on remote embodied referring expressions is accepted to CVPR as an oral presentation."
  - "(February 2020) Delighted to be co-organizing workshops on [Embodied Vision, Actions and Language (EVAL)](https://askforalfred.com/EVAL/) at ECCV 2020 and [Advances in Language and Vision Research (ALVR)](https://alvr-workshop.github.io/) at ACL 2020."
  - "(October 2019) Excited to announce: from January, I'll be a Research Scientist at Google in Austin! Looking forward to collaborating with [Jason Baldridge](https://ai.google/research/people/JasonBaldridge/), [Radu Soricut](https://ai.google/research/people/105783) and others!"
  - "(September 2019) Our paper [Chasing Ghosts: Instruction Following as Bayesian State Tracking](https://arxiv.org/abs/1907.02022) is accepted to [NeurIPS 2019](https://neurips.cc/)."
  - "(July 2019) Our [nocaps](https://nocaps.org/) paper is accepted to [ICCV 2019](http://iccv2019.thecvf.com/)."
  - "(May 2019) Recognized as a [CVPR 2019 outstanding reviewer](http://cvpr2019.thecvf.com/files/CVPR_2019_Program_Guide.pdf)."
  - "(May 2019) We have released the [nocaps](https://nocaps.org/) benchmark for **n**ovel **o**bject **cap**tioning at **s**cale."
  - "(April 2019) We have a paper accepted to [ICML 2019](https://icml.cc/). Congratulations Ashwin."
  - "(February 2019) Co-organizing the [Visual Question Answering and Dialog Workshop](https://visualqa.org/workshop.html) and the [Habitat: Embodied Agents Challenge and Workshop](https://facebookmicrosites.github.io/habitat-website/workshop/) at CVPR 2019."
  - "(February 2019) We have a paper accepted to [CVPR 2019](http://cvpr2019.thecvf.com/). Congratulations to Huda and Vincent."
  - "(February 2019) I am serving as an Area Chair for [NeurIPS 2019](https://neurips.cc/Conferences/2019)."
  - "(December 2018) Co-organizing the [Visually Grounded Interaction and Language Workshop](https://nips2018vigil.github.io/) at NeurIPS."
  - "(September 2018) Recognized as a [NeurIPS 2018 outstanding reviewer](https://media.nips.cc/Conferences/NIPS2018/NIPS-2018-Conference-Book.pdf)."
  - "(September 2018) Our paper is accepted to [NeurIPS 2018](https://nips.cc/)."
  - "(August 2018) We have one paper accepted to [EMNLP 2018](http://emnlp2018.org/)."
  - "(July 2018) Excited to announce that I have started as a research scientist at Georgia Tech, collaborating with [Dhruv Batra](https://www.cc.gatech.edu/~dbatra/) and [Devi Parikh](https://www.cc.gatech.edu/~parikh/)."
  - "(July 2018) Slides available from our tutorial on [Connecting Language and Vision to Actions](https://lvatutorial.github.io/) at [ACL 2018](http://acl2018.org/)."
  - "(June 2018) Presenting an invited talk at the [VQA Challenge and Visual Dialog workshop](http://visualqa.org/workshop) at CVPR."
  - "(May 2018) Our Vision and Language Navigation (VLN) [challenge and leaderboard](https://evalai.cloudcv.org/web/challenges/challenge-page/97/overview) is now live on EvalAI!"
  - "(May 2018) Very excited to be an organizer of the ECCV 2018 workshop on [Visual Learning and Embodied Agents in Simulation Environments](https://eccv18-vlease.github.io/)."
  - "(April 2018) We have a paper accepted to [ACL 2018](http://acl2018.org/)."
  - "(February 2018) We have three papers accepted to CVPR 2018, including [one oral](/up-down-attention/) and [one spotlight](https://bringmeaspoon.org/)! Congratulations to all co-authors."
  - "(February 2018) We have published code for our recently [state-of-the-art image captioning model](https://github.com/peteanderson80/Up-Down-Captioner)."
  - "(December 2017) We will be presenting our work on [Vision-and-Language Navigation](https://bringmeaspoon.org/) at the NIPS 2017 [ViGIL workshop](https://nips2017vigil.github.io)."
  - "(Sept 2017) We have been selected to receive a [Facebook ParlAI research award](https://research.fb.com/announcing-the-winners-of-the-facebook-parlai-research-awards/)."
  - "(26 July 2017) We are 1st in the 2017 Visual Question Answering (VQA) Challenge at CVPR! We are also 1st on the MSCOCO image captioning leaderboard. Details and code are on the [project page](/up-down-attention/)."
  - "(July 2017) Our paper on [out-of-domain image captioning](/images/constrained-beam-search.pdf) is accepted to EMNLP 2017."
  - "(April 2017) I am currently interning with the Deep Learning Technology Center working with [Lei Zhang](https://www.microsoft.com/en-us/research/people/leizhang/) and [Xiaodong He](https://www.microsoft.com/en-us/research/people/xiaohe/) at Microsoft AI & Research, Redmond, Washington USA."
  - "(July 2016) We have released a new [image caption evaluation metric (SPICE)](/spice/) that improves on CIDEr and METEOR. The paper will appear at ECCV 2016."
